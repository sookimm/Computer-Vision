{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"city.mp4\")\n",
    "\n",
    "# 0 for the default webcam\n",
    "# Path to a video file for playback\n",
    "# 1, 2, ... for external cameras\n",
    "# IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, frame = cap.read()     # tuple type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1080, 1920, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.shape     # 3 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-28 17:44:37.873 Python[39377:12742631] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-01-28 17:44:37.873 Python[39377:12742631] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if frame is None:\n",
    "        break\n",
    "\n",
    "    frame = cv2.resize(frame, (500, 300))\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) == ord('q'):      # waitKey() for speed. can put the number (getting greater, getting slower)\n",
    "        break\n",
    "    \n",
    "cap.release()    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('a') #ASCII"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FPS (Frame Per Second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_fps = 10\n",
    "\n",
    "video_path = \"city.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "original_fps = int(cap.get(cv2.CAP_PROP_FPS))       # get original fps from original video\n",
    "frame_interval = int(original_fps / desired_fps)\n",
    "\n",
    "frame_count = 0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Skip frames to match the desired FPS\n",
    "    if frame_count % frame_interval == 0:\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "    frame_count += 1\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawing Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blank image\n",
    "# np.zeros((height, width, channels), dtype)\n",
    "image = np.zeros((400, 400, 3), dtype=np.uint8)\n",
    "\n",
    "# cv2.line(base image, pt1, pt2, colour, line thickness)\n",
    "cv2.line(image, (50, 50), (350, 350), (255, 255, 255), thickness=3)\n",
    "\n",
    "# draw rectangle line(pt1: top-left corner, pt2: bottom-right corner)\n",
    "cv2.rectangle(image, (100, 100), (300,300), (0, 0, 255), thickness=5)\n",
    "\n",
    "# cv2.circle(image, centre(centre of circle x,y), radius(should be int), colour, thickness)\n",
    "cv2.circle(image, (200, 200), 100, (0, 255, 0), thickness=5)\n",
    "\n",
    "cv2.imshow(\"line example\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blank image\n",
    "# np.zeros((height, width, channels), dtype)\n",
    "image = np.zeros((400, 400, 3), dtype=np.uint8)\n",
    "\n",
    "# cv2.putText(image, text, org(start point: left-bottom), font, font_scale(the greater the bigger), colour, thickness, line_type)\n",
    "cv2.putText(image, \"Hello OpenCV!\", (50, 200), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), thickness=2, lineType=cv2.LINE_AA)\n",
    "\n",
    "cv2.imshow(\"text example\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Point Operator\n",
    "- The value of each pixel in the output depends only on the value of the same pixel in the input (and possibly some global information or some parameters)\n",
    "- Each pixel is processed independently\n",
    "- No influence from neighboring pixels\n",
    "- e.g., Contrast Adjustment, Thresholding, Brightness Adjustment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Addition and Substraction\n",
    "- Using arithmetic operations in Numpy does not work when values can go above 255 or lower than 0\n",
    "- OpenCV's saturated arithmetic ensures that values above 255 are set to 255, and values below 0 are clamped to 0\n",
    "- Use OpenCV functions instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = cv2.imread(\"Cat.jpg\")\n",
    "\n",
    "# make brighter\n",
    "# cat = cv2.add(cat, 110)\n",
    "\n",
    "# only for last channel\n",
    "# cat = cv2.add(cat[:,:,2], 110)\n",
    "\n",
    "# make darker\n",
    "cat = cv2.subtract(cat, 50)\n",
    "\n",
    "cv2.imshow(\"cat\", cat)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiply and Divide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = cv2.imread(\"Cat.jpg\")\n",
    "\n",
    "# make bright colors brighter - use scale > 1\n",
    "# make dark colors darker - use scale < 1\n",
    "cat = cv2.multiply(cat, np.ones(cat.shape, dtype=\"uint8\"), scale=0.5)\n",
    "\n",
    "cv2.imshow(\"cat\", cat)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thresholding\n",
    "- A technique to segment an image by converting it into binary form\n",
    "- Separates foreground (object) from background based on intensity values\n",
    "- Object detection and segmentation\n",
    "- Preprocessing for OCR and feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = cv2.imread(\"Cat.jpg\")\n",
    "\n",
    "#  retval, dst = cv2.threshold(image(gray scale is recommended), thresh(threshold value), maxval, type)\n",
    "_, cat = cv2.threshold(cv2.cvtColor(cat, cv2.COLOR_BGR2GRAY), 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "cv2.imshow(\"cat\", cat)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Blend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-28 18:10:32.389 Python[39377:12742631] _TIPropertyValueIsValid called with 16 on nil context!\n",
      "2025-01-28 18:10:32.389 Python[39377:12742631] imkxpc_getApplicationProperty:reply: called with incorrect property value 16, bailing.\n",
      "2025-01-28 18:10:32.389 Python[39377:12742631] Text input context does not respond to _valueForTIProperty:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "img1 = cv2.imread(\"Dog and Cat.jpg\")\n",
    "img1 =cv2.resize(src=img1, dsize=(720,1028))\n",
    "\n",
    "img2 = cv2.imread(\"Cat.jpg\")\n",
    "img2 = cv2.resize(img2, (img1.shape[1], img1.shape[0]))\n",
    "img3 = cv2.addWeighted(img1, 0.6, img2, 0.4, 0)     # img1: forefront, img2: background\n",
    "\n",
    "cv2.imshow('shape', img3)\n",
    "cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computer_vision_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
